{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_train = []\n",
    "lines_test = []\n",
    "classes = []\n",
    "categories = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "with open(\"data/train.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()\n",
    "    for l in lines:\n",
    "        lines_train.append(l.rstrip().split(' '))\n",
    "    \n",
    "with open(\"data/train.labels\", \"r\") as fh:\n",
    "    lines = fh.readlines()\n",
    "    for l in lines:\n",
    "        classes.append(l.rstrip())\n",
    "    \n",
    "with open(\"data/test.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()\n",
    "    for l in lines:\n",
    "        lines_test.append(l.rstrip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887\n",
      "5296\n",
      "21186\n"
     ]
    }
   ],
   "source": [
    "print(len(lines_train[0]))\n",
    "print(len(lines_test))\n",
    "print(len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(lines_train[:1])\n",
    "# print(lines_test[:1])\n",
    "# print(classes[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_std = StandardScaler().fit_transform(lines_train)\n",
    "X_test_std = StandardScaler().fit_transform(lines_test)\n",
    "# vectorizer = HashingVectorizer()\n",
    "# X_train_std = vectorizer.transform(lines_train)\n",
    "# X_test_std = vectorizer.transform(lines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(21186, 887)\n",
      "<type 'numpy.ndarray'>\n",
      "(5296, 887)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_std))\n",
    "print(X_train_std.shape)\n",
    "print(type(X_test_std))\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=48)\n",
    "# pca.fit(X_train_std)\n",
    "# X_train_svd = pca.transform(X_train_std)\n",
    "# X_test_svd = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=48, n_iter=10, random_state=42)\n",
    "svd.fit(X_train_std)\n",
    "X_train_svd = svd.transform(X_train_std)\n",
    "X_test_svd = svd.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.86705424e+01   1.72106524e+00  -2.50534664e-01 ...,  -2.38275111e-15\n",
      "    4.87457297e-15  -9.92261828e-16]\n",
      " [  2.86705424e+01   3.85705164e+00   4.36661196e+00 ...,  -2.40064045e-15\n",
      "    5.39152056e-15  -9.02056208e-16]\n",
      " [  2.86705424e+01  -9.69232395e+00  -3.26048524e+00 ...,  -2.02214547e-15\n",
      "    4.48252546e-15  -1.08246745e-15]\n",
      " ..., \n",
      " [  2.86705424e+01  -3.83621228e+00  -4.72358943e+00 ...,  -3.05712487e-15\n",
      "    4.02108902e-15  -2.76861867e-15]\n",
      " [  2.86705424e+01  -1.08585838e+01  -2.17295332e+00 ...,  -2.87866519e-15\n",
      "    3.08086889e-15  -2.72351586e-15]\n",
      " [  2.86705424e+01  -2.02996547e+00  -4.83510568e+00 ...,  -2.95759511e-15\n",
      "    4.13211132e-15  -3.02188830e-15]]\n",
      "[[-1.04637016  4.58987522 -2.39569287 ...,  2.04552982 -1.33351615\n",
      "  -0.05464101]\n",
      " [-1.04637016 -8.97980057 -0.52335762 ...,  2.04552982 -1.33351615\n",
      "  -0.05464101]\n",
      " [-1.04637016 -7.05852548  1.29715189 ...,  2.04552982 -1.33351615\n",
      "  -0.05464101]\n",
      " ..., \n",
      " [-1.04637016  1.77707858 -0.67312864 ...,  2.04552982 -1.33351615\n",
      "  -0.05464101]\n",
      " [-1.04637016  7.08558903 -4.44446854 ...,  2.04552982 -1.33351615\n",
      "  -0.05464101]\n",
      " [-1.04637016 -7.24467992  1.39843341 ...,  2.04552982 -1.33351615\n",
      "  -0.05464101]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_svd)\n",
    "print(X_test_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = HashingVectorizer(stop_words='english')\n",
    "# X_train = vectorizer.transform(lines_train)\n",
    "# X_test = vectorizer.transform(lines_test)\n",
    "# vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "# X_train = vectorizer.fit_transform(docs_train)\n",
    "\n",
    "\n",
    "y_train = np.asarray(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(k_neighbors=2, ratio=\"minority\")\n",
    "X_resampled, y_resampled = smote.fit_sample(X_train_svd, y_train)\n",
    "# X_res_vis = pca.transform(X_resampled)\n",
    "print(type(X_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler(ratio=\"minority\")\n",
    "# X_resampled, y_resampled = ros.fit_sample(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import ADASYN \n",
    "# ada = ADASYN(random_state=10, n_neighbors=2)\n",
    "# X_resampled, y_resampled = ada.fit_sample(X_train_pca, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31558, 48)\n",
      "(31558,)\n"
     ]
    }
   ],
   "source": [
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_names = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "def classify(clf, X_train, Y_train, X_test):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    print(type(pred))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.107s\n",
      "test time:  5.405s\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# pred1 = classify(KNeighborsClassifier(n_neighbors=4), X_train_pca, y_train, X_test_pca)\n",
    "pred1 = classify(KNeighborsClassifier(n_neighbors=4), X_resampled, y_resampled, X_test_svd)\n",
    "# pred1 = classify(SVC(gamma=2), X_resampled, y_resampled, X_test_pca)\n",
    "# pred1 = classify(AdaBoostClassifier(), X_resampled, y_resampled, X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeToFile(pred):\n",
    "    with open('output/output_KNeighborSVD48.dat','w+') as f:\n",
    "        for p in pred:\n",
    "            f.write(str(p)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred1))\n",
    "writeToFile(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    content = []\n",
    "    with open(filename) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(p1, p2):\n",
    "    match = 0\n",
    "    total = len(p1)\n",
    "    for i in range(0,total-1):                \n",
    "        if(p1[i]==p2[i]):\n",
    "            match = match+1\n",
    "    per = ((float(match)/float(total))*100)\n",
    "    return per\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.4410876133\n",
      "99.3013595166\n"
     ]
    }
   ],
   "source": [
    "# p1 = readFile(\"output/output_KNeighbor1.dat\")\n",
    "p2 = readFile(\"submissions/Submission2_0.8168/output_KNeighbor.dat\")\n",
    "print(compare(pred1,p2))\n",
    "print(compare(pred1,readFile(\"submissions/Submission11_0.81/output_KNeighbor.dat\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '1' '2' '2' '1' '2' '1' '1' '1' '1']\n",
      "['1', '1', '2', '2', '2', '2', '1', '1', '1', '1']\n",
      "5296\n",
      "5296\n"
     ]
    }
   ],
   "source": [
    "print(pred1[:10])\n",
    "print(p2[:10])\n",
    "print(len(pred1))\n",
    "print(len(p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
