{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_train = []\n",
    "lines_test = []\n",
    "classes = []\n",
    "categories = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "with open(\"data/train.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()\n",
    "    for l in lines:\n",
    "        lines_train.append(l.rstrip().split(' '))\n",
    "    \n",
    "with open(\"data/train.labels\", \"r\") as fh:\n",
    "    lines = fh.readlines()\n",
    "    for l in lines:\n",
    "        classes.append(l.rstrip())\n",
    "    \n",
    "with open(\"data/test.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()\n",
    "    for l in lines:\n",
    "        lines_test.append(l.rstrip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21186\n",
      "5296\n",
      "21186\n"
     ]
    }
   ],
   "source": [
    "print(len(lines_train))\n",
    "print(len(lines_test))\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lines_train[:1])\n",
    "# print(lines_test[:1])\n",
    "# print(classes[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_std = StandardScaler().fit_transform(lines_train)\n",
    "X_test_std = StandardScaler().fit_transform(lines_test)\n",
    "# vectorizer = HashingVectorizer()\n",
    "# X_train_std = vectorizer.transform(lines_train)\n",
    "# X_test_std = vectorizer.transform(lines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(21186, 887)\n",
      "<type 'numpy.ndarray'>\n",
      "(5296, 887)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_std))\n",
    "print(X_train_std.shape)\n",
    "print(type(X_test_std))\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=25)\n",
    "# pca.fit(X_train_std)\n",
    "# X_train_pca = pca.transform(X_train_std)\n",
    "# X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=30, n_iter=10, random_state=42)\n",
    "svd.fit(X_train_std)\n",
    "X_train_pca = svd.transform(X_train_std)\n",
    "X_test_pca = svd.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.86705424e+01   1.72106524e+00  -2.50534664e-01 ...,   3.16462380e-02\n",
      "    7.08348239e-02  -1.83379140e-02]\n",
      " [  2.86705424e+01   3.85705164e+00   4.36661196e+00 ...,   1.14984057e-01\n",
      "   -1.01723168e-02   5.48227309e-02]\n",
      " [  2.86705424e+01  -9.69232395e+00  -3.26048524e+00 ...,  -2.01424366e-01\n",
      "    7.05864824e-02   1.02195643e-01]\n",
      " ..., \n",
      " [  2.86705424e+01  -3.83621228e+00  -4.72358943e+00 ...,   1.34625537e-02\n",
      "    3.03190263e-01   6.84452291e-02]\n",
      " [  2.86705424e+01  -1.08585838e+01  -2.17295332e+00 ...,  -5.45009950e-01\n",
      "   -3.93588729e-01  -3.49016904e-01]\n",
      " [  2.86705424e+01  -2.02996547e+00  -4.83510568e+00 ...,  -1.62523348e-01\n",
      "    7.57988058e-02   8.26159794e-02]]\n",
      "[[ -1.04637016e+00   4.58987522e+00  -2.39569287e+00 ...,  -1.27088418e-01\n",
      "    6.14520217e-02  -1.17874872e-02]\n",
      " [ -1.04637016e+00  -8.97980057e+00  -5.23357622e-01 ...,   1.70590314e-01\n",
      "   -2.05146247e-01   5.09779166e-02]\n",
      " [ -1.04637016e+00  -7.05852548e+00   1.29715189e+00 ...,   2.85546332e-01\n",
      "    1.44935570e-02  -1.95291661e-02]\n",
      " ..., \n",
      " [ -1.04637016e+00   1.77707858e+00  -6.73128642e-01 ...,   3.59418806e-02\n",
      "   -8.83270139e-03  -4.25574278e-02]\n",
      " [ -1.04637016e+00   7.08558903e+00  -4.44446854e+00 ...,  -1.11333314e-01\n",
      "    7.37587369e-02  -6.17086043e-02]\n",
      " [ -1.04637016e+00  -7.24467992e+00   1.39843341e+00 ...,   2.63560065e-01\n",
      "    1.44704075e-01   1.14300928e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca)\n",
    "print(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = HashingVectorizer(stop_words='english')\n",
    "# X_train = vectorizer.transform(lines_train)\n",
    "# X_test = vectorizer.transform(lines_test)\n",
    "# vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "# X_train = vectorizer.fit_transform(docs_train)\n",
    "\n",
    "\n",
    "y_train = np.asarray(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE(k_neighbors=2)\n",
    "# X_resampled, y_resampled = smote.fit_sample(X_train_pca, y_train)\n",
    "# # X_res_vis = pca.transform(X_resampled)\n",
    "# print(type(X_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(ratio=\"minority\")\n",
    "X_resampled, y_resampled = ros.fit_sample(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import ADASYN \n",
    "# ada = ADASYN(random_state=10, n_neighbors=2)\n",
    "# X_resampled, y_resampled = ada.fit_sample(X_train_pca, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31558, 30)\n",
      "(31558,)\n"
     ]
    }
   ],
   "source": [
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_names = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "def classify(clf, X_train, Y_train, X_test):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    print(type(pred))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.177s\n",
      "test time:  3.496s\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# pred1 = classify(KNeighborsClassifier(n_neighbors=4), X_train_pca, y_train, X_test_pca)\n",
    "pred1 = classify(KNeighborsClassifier(n_neighbors=4), X_resampled, y_resampled, X_test_pca)\n",
    "# pred1 = classify(SVC(gamma=2), X_resampled, y_resampled, X_test_pca)\n",
    "# pred1 = classify(AdaBoostClassifier(), X_resampled, y_resampled, X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeToFile(pred):\n",
    "    with open('output/output_KNeighbor.dat','w+') as f:\n",
    "        for p in pred:\n",
    "            f.write(str(p)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred1))\n",
    "writeToFile(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    content = []\n",
    "    with open(filename) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(p1, p2):\n",
    "    match = 0\n",
    "    total = len(p1)\n",
    "    for i in range(0,total-1):                \n",
    "        if(p1[i]==p2[i]):\n",
    "            match = match+1\n",
    "    per = ((float(match)/float(total))*100)\n",
    "    return per\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.5166163142\n",
      "82.2318731118\n"
     ]
    }
   ],
   "source": [
    "# p1 = readFile(\"output/output_KNeighbor1.dat\")\n",
    "p2 = readFile(\"submissions/Submission2_0.8168/output_KNeighbor.dat\")\n",
    "print(compare(pred1,p2))\n",
    "print(compare(pred1,readFile(\"submissions/Submission10/output_KNeighbor1.dat\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '1' '2' '2' '1' '2' '1' '1' '1' '1']\n",
      "['1', '1', '2', '2', '2', '2', '1', '1', '1', '1']\n",
      "5296\n",
      "5296\n"
     ]
    }
   ],
   "source": [
    "print(pred1[:10])\n",
    "print(p2[:10])\n",
    "print(len(pred1))\n",
    "print(len(p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
